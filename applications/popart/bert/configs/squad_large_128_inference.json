{
    "task": "SQUAD",
    "layers_per_ipu": 6,
    "num_layers": 24,
    "hidden_size": 1024,
    "attention_heads": 16,
    "sequence_length": 128,
    "popart_dtype": "FLOAT16",
    "no_dropout": true,
    "loss_scaling": 1.0,
    "stochastic_rounding": true,
    "batches_per_step": 128,
    "epochs": 1,
    "epochs_per_save": 1,
    "input_files": [
        "data/squad/dev-v1.1.json"
    ],
    "vocab_file": "data/ckpts/uncased_L-12_H-768_A-12/vocab.txt",
    "do-lower-case" : true,
    "squad_results_dir": "data/squad/results",
    "squad_evaluate_script": "data/squad/evaluate-v1.1.py",
    "shuffle": false,
    "execution_mode": "PIPELINE",
    "inference": true,
    "squeeze_model": true,
    "split_linear_layers": true,
    "use_default_available_memory_proportion": false,
    "low_latency_inference": true,
    "max_copy_merge_size": -1,
    "max_matmul_memory": 104858
}
