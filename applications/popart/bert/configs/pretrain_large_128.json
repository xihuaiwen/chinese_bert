{
	"task": "PRETRAINING",
	"num_layers": 24,
	"layers_per_ipu": 2,
	"hidden_size": 1024,
	"attention_heads": 16,
	"sequence_length": 128,
	"mask_tokens": 20,
	"popart_dtype": "FLOAT16",
	"no_dropout": false,
	"no_attn_dropout": true,
	"no_cls_layer": true,
	"learning_rate": 8e-6,
	"lr_schedule_by_step": {
		"0": 8e-06,
		"50": 0.00040,
		"512": 0.00036103368084499824,
		"1024": 0.00034301399659075803,
		"1536": 0.00032589369939609215,
		"2048": 0.0003096278996241172,
		"2560": 0.0002941739481410544,
		"3072": 0.0002794913244896592,
		"3584": 0.000265541530644067,
		"4096": 0.00025228799006747995,
		"4608": 0.00023969595180802273,
		"5120": 0.0002277323993813046,
		"5632": 0.00021636596420077786,
		"6144": 0.00020556684332890515,
		"6656": 0.0001953067213334781,
		"7168": 0.0001855586960441946,
		"7680": 0.00017629720801482578,
		"8192": 0.00016749797350602334,
		"8704": 0.0001591379208130463,
		"9216": 0.00015119512977145776,
		"9728": 0.0001436487742821752,
		"10240": 0.00013647906770517375,
		"10752": 0.00012966721097866475,
		"11264": 0.00012319534332771656,
		"11776": 0.00011704649543307581,
		"12288": 0.00011120454493739638,
		"12800": 0.00010565417417221378,
		"13312": 0.00010038082999482336,
		"13824": 9.537068562975549e-05,
		"14336": 9.061060441479422e-05,
		"14848": 8.608810535648209e-05,
		"15360": 8.179133040479668e-05,
		"15872": 7.770901336119253e-05,
		"16384": 7.38304503384855e-05,
		"16896": 7.014547169512438e-05,
		"17408": 6.664441537026155e-05,
		"17920": 6.331810154970658e-05,
		"18432": 6.015780859633672e-05,
		"18944": 5.715525018185348e-05,
		"19456": 5.4302553559924525e-05,
		"19968": 5.159223892374266e-05,
		"20480": 4.9017199793877374e-05,
		"20992": 4.657068438499535e-05,
		"21504": 4.424627790259356e-05,
		"22016": 4.203788572332648e-05,
		"22528": 3.9939717414826207e-05,
		"23040": 3.794627155311521e-05,
		"23552": 3.605232129780272e-05,
		"24064": 3.4252900687242735e-05,
		"24576": 3.2543291617719505e-05,
		"25088": 3.091901147251962e-05,
		"25600": 2.9375801368453905e-05,
		"26112": 2.7909614989011705e-05,
		"26624": 2.6516607974867443e-05,
		"27136": 2.5193127843921655e-05,
		"27648": 2.3935704414446444e-05,
		"28160": 2.2741040706224925e-05,
		"28672": 2.160600429582717e-05,
		"29184": 2.052761910335612e-05,
		"29696": 1.950305758912832e-05,
		"30208": 1.8529633339828883e-05,
		"30720": 1.7604794024701627e-05,
		"31232": 1.6726114703305416e-05,
		"31744": 1.589129146728947e-05,
		"32256": 1.50981353995164e-05,
		"32768": 1.4344566834693612e-05,
		"33280": 1.3628609906464524e-05
	  },
	"loss_scaling": 20.0,
	"velocity_scaling": 20.0,
	"momentum": 0.984375,
	"pipeline_lr_scaling": false,
	"pipeline_momentum_scaling": false,
	"stochastic_rounding": true,
	"batches_per_step":  128,
	"epochs": 8,
	"epochs_per_save": 1,
	"steps_per_save": 512,
	"steps_per_log": 100,
	"aggregate_metrics_over_steps": 1,
	"gradient_accumulation_factor": 64,
	"input_files": [
		"data/wikipedia/AA/sequence_128/wiki_00_tokenised",
		"data/wikipedia/AA/sequence_128/wiki_01_tokenised",
		"data/wikipedia/AA/sequence_128/wiki_02_tokenised",
		"data/wikipedia/AA/sequence_128/wiki_03_tokenised",
		"data/wikipedia/AA/sequence_128/wiki_04_tokenised",
		"data/wikipedia/AA/sequence_128/wiki_05_tokenised",
		"data/wikipedia/AA/sequence_128/wiki_06_tokenised",
		"data/wikipedia/AA/sequence_128/wiki_07_tokenised",
		"data/wikipedia/AA/sequence_128/wiki_08_tokenised",
		"data/wikipedia/AA/sequence_128/wiki_09_tokenised",
		"data/wikipedia/AA/sequence_128/wiki_10_tokenised",
		"data/wikipedia/AA/sequence_128/wiki_11_tokenised",
		"data/wikipedia/AA/sequence_128/wiki_12_tokenised",
		"data/wikipedia/AA/sequence_128/wiki_13_tokenised"
	],
	"duplication_factor": 6,
	"epochs_to_cache": 1,
	"vocab_length": 30400,
	"projection_serialization_steps": 5,
	"max_matmul_memory": 60000,
	"shuffle": true,
	"execution_mode": "PIPELINE",
	"checkpoint_dir": "checkpoints/pretrain_large",
	"no_validation": true
}
