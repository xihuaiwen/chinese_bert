{
    "task": "pretraining",
    "attention_probs_dropout_prob": 0.0,
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.1,
    "hidden_size": 768,
    "initializer_range": 0.02,
    "intermediate_size": 3072,
    "max_position_embeddings": 512,
    "vocab_size": 52000,
    "num_attention_heads": 12,
    "num_hidden_layers": 12,
    "type_vocab_size": 2,
    "seq_length": 256,
    "num_train_steps":1000000,
    "max_predictions_per_seq": 40,
    "use_attention_projection_bias": true,
    "use_cls_layer": true,
    "use_qkv_bias": true,
    "pipeline_stages": [
     ["emb"],
     ["emb", "pos"],
     ["hid","hid"],
     ["hid","hid"],
     ["hid","hid"],
     ["hid","hid"],
     ["hid","hid"],
     ["hid","hid"],
     ["mlm"],
     ["mlm","nsp"]], 
    "device_mapping":[0,1,2,3,4,5,6,7,0,1],
    "batch_size": 16,
    "batches_per_step": 1,
    "epochs": 1,
    "base_learning_rate": 2.5e-4,
    "lr_schedule": "polynomial",
    "loss_scaling": 1,
    "optimizer": "adamw",
    "beta1": 0.9,
    "beta2": 0.999,
    "epsilon": 1e-6,
    "weight_decay": 0.01,
    "pipeline_depth":20,
    "pipeline_schedule": "Grouped",
    "replicas": 1,
    "half_partial":"half",
    
    "precision": "16",
    "seed": 1234,
    "steps_per_tensorboard": 128,
    "steps_per_ckpts": 1000,
    "steps_per_logs": 1,
    "warmup_steps": 10000,
    "available_memory_proportion":0.11,
    "variable_offloading": false,
    "parallell_io_threads": 16,
    "matmul_serialize_factor":4,
    "duplicate_factor":5,
    "no_outlining": false,
    "stochastic_rounding": true,
    "xla_recompute": true,
    "fp_exceptions": false,

    "recomputation_mode":"RecomputeAndBackpropagateInterleaved",
    "reduction_type": "mean",
  
    "init_checkpoint":"",
    "restore_dir": "",
    "save_path": "/localdata/liguoying/ckpts/cn_bert_12l/phase1",
    "train_file":"/localdata/liguoying/datasets/chiese_bert/bert/*.tfrecord"
  }
  
