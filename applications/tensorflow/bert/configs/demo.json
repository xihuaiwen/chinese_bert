{
    "task": "pretraining",
    "attention_probs_dropout_prob": 0.0,
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.1,
    "hidden_size": 128,
    "initializer_range": 0.02,
    "intermediate_size": 512,
    "max_position_embeddings": 512,
    "num_attention_heads": 2,
    "num_hidden_layers": 2,
    "hidden_layers_per_stage": 1,
    "type_vocab_size": 2,
    "vocab_size": 30400,
    "seq_length": 128,

    "batch_size": 1,
    "batches_per_step": 1,
    "num_train_steps": 100,
    "max_predictions_per_seq": 20,
    "base_learning_rate": 0.0001,
    "lr_schedule": "exponential",
    "loss_scaling": 1.0,
    "optimizer": "momentum",
    "momentum": 0.9,
    "pipeline_depth": 16,
    "pipeline_schedule": "Grouped",
    "replicas": 1,
    "half_partial": "float",
    "precision": "16",
    "seed": 1234,
    "steps_per_tensor_logs": 100,
    "steps_per_logs": 1,
    "ckpts_per_epoch": 1,
    "warmup_steps": 0,
    "decay_steps": 512,
    "decay_rate": 0.051,
    "available_memory_proportion": 0.6,
    "variable_offloading": false,
    "parallell_io_threads": 16,
    "embedding_cut_num": 2,
    "matmul_serialize_factor": 4,
    "duplicate_factor":5,
    "no_outlining": true,
    "stochastic_rounding": true,
    "xla_recompute": true,
    "fp_exceptions": false,
    "do_train": true,

    "init_checkpoint": "",
    "restore_dir": "",
    "variable_filter": "",
    "save_path": "./checkpoint/phase1",
    "train_file": "Datasets/sample.tfrecord"
}